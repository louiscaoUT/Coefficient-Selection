{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "train = pd.read_csv(\"training_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gurobi Template for MIQP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miqp(k, batches):\n",
    "    # batches is a 2D array comprised of all the batches we're not trying to solve the error for, should have len of 225 (9*25)\n",
    "    M = 30\n",
    "    timelimit = 3600  # in units of seconds\n",
    "    # init model, betas, and z\n",
    "    model = gp.Model()\n",
    "    beta = model.addMVar(51, lb=-np.inf)\n",
    "    z = model.addMVar(50, vtype=\"B\")\n",
    "    # obj, let i be the row within our batch, and j be each column in the row, loop through all 51 data points (j) in every row (i)\n",
    "    model.setObjective(\n",
    "        gp.quicksum(\n",
    "            (\n",
    "                beta[0]\n",
    "                + gp.quicksum(\n",
    "                    beta[j] * batches[i][j] for j in range(1, len(batches[i]))\n",
    "                )\n",
    "                - batches[i][0]\n",
    "            )\n",
    "            * (\n",
    "                beta[0]\n",
    "                + gp.quicksum(\n",
    "                    beta[j] * batches[i][j] for j in range(1, len(batches[i]))\n",
    "                )\n",
    "                - batches[i][0]\n",
    "            )\n",
    "            for i in range(len(batches))\n",
    "        )\n",
    "    )\n",
    "    # constraints\n",
    "    model.addConstr(gp.quicksum(z[i] for i in range(50)) <= k)\n",
    "    model.addConstrs(beta[i] <= z[i - 1] * M for i in range(1, 51))\n",
    "    model.addConstrs(beta[i] >= z[i - 1] * -M for i in range(1, 51))\n",
    "    model.write(\"model.lp\")\n",
    "    model.Params.OutputFlag = 0\n",
    "    model.setParam(\"TimeLimit\", timelimit)  # 1 hour per miqp\n",
    "    model.optimize()\n",
    "    # get and return betas for current batch so we can fit on batch we didn't include to get squared error\n",
    "    return beta.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Batch Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_batches(batches, n):\n",
    "    # inputs all batches[i] where i != n into a tuple to add to a numpy array\n",
    "    batches_to_add = tuple([batches[i] for i in range(len(batches)) if i != n])\n",
    "    new_batch = np.concatenate(batches_to_add)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Squared Error Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squared_error(batch, beta_list):\n",
    "    # let batch be the batch that was not fitted to get betas\n",
    "    # let beta_list be betas acquired from fitting all other batches\n",
    "    squared_error = 0\n",
    "    for i in batch:\n",
    "        # (y - yhat)^2 | yhat = B0 + sum(all the betas * all the x's of batch) of that particular row\n",
    "        yhat = beta_list[0] + sum(np.multiply(beta_list[1:], i[1:]))\n",
    "        squared_error += np.square(i[0] - yhat)\n",
    "\n",
    "    return squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation function\n",
    "def cross_validation(batches):\n",
    "    # let batches be a 3D array: the training data split into 10 batches with 25 rows in every batch and 51 data points (1 y, 50 x's) in every row\n",
    "    k_list = []  # list to grab all k's and their squared errors\n",
    "    for k in range(5, 55, 5):\n",
    "        sum_squared_error = 0  # store sum of squared errors for a particular k\n",
    "        # 10 fold cross validation\n",
    "        for i in range(10):\n",
    "            # get all batches excluding batches[i]\n",
    "            new_batches = get_new_batches(batches, i)\n",
    "            # get betas fit from iteration of cross validation\n",
    "            beta_list = miqp(k, new_batches)\n",
    "            # get squared error using betas fit from 9 other batches to batch not included in new_batches\n",
    "            sum_squared_error += get_squared_error(batches[i], beta_list)\n",
    "        # append k and squared array into k_list\n",
    "        k_list.append((k, sum_squared_error))\n",
    "\n",
    "    return k_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle rows and batch rows into clusters of 10 with length 25\n",
    "training_rows = np.array(\n",
    "    [train.iloc[i] for i in range(train.shape[0])]\n",
    ")  # get all rows from training data into 1 array\n",
    "np.random.shuffle(training_rows)  # shuffle\n",
    "train_batches = np.array_split(\n",
    "    training_rows, 10\n",
    ")  # batch/cluster into 10 batches/clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best value of k\n",
    "k_list = cross_validation(train_batches)  # get all k's and their sum of squared errors\n",
    "best_k = sorted(k_list, key=lambda x: x[1])[0][0]  # get best k\n",
    "\n",
    "# display best_k and its mean squared error\n",
    "print(\n",
    "    f\"the best k: {best_k}\",\n",
    "    f\"cross validation results:\",\n",
    "    np.array([[x, y / train.shape[0]] for x, y in k_list]),\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best_k number of betas fit on the entire training set\n",
    "training_set = np.array(\n",
    "    [train.iloc[i] for i in range(train.shape[0])]\n",
    ")  # get all rows from training data into 1 array\n",
    "testing_set = np.array(\n",
    "    [test.iloc[i] for i in range(test.shape[0])]\n",
    ")  # get all rows from testing data into 1 array\n",
    "\n",
    "training_betas = miqp(best_k, training_set)\n",
    "direct_variable_squared_error = get_squared_error(testing_set, training_betas)\n",
    "# mean squared error\n",
    "direct_variable_squared_error / len(testing_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prereq\n",
    "x_train = [train.iloc[i][1:] for i in range(train.shape[0])]\n",
    "y_train = [train.iloc[i][0] for i in range(train.shape[0])]\n",
    "# get lambda/alpha with cross validation\n",
    "lasso = LassoCV(cv=10).fit(x_train, y_train)\n",
    "# show intercept & coefficients\n",
    "lasso_model = Lasso(alpha=lasso.alpha_).fit(\n",
    "    x_train, y_train\n",
    ")  # 0.07638765995113507 = lambda/alpha\n",
    "(lasso_model.intercept_, lasso_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "x_test = [test.iloc[i][1:] for i in range(test.shape[0])]\n",
    "test_predictions = lasso_model.predict(x_test)\n",
    "\n",
    "# get squared error of predictions\n",
    "lasso_squared_error = 0\n",
    "for i in range(test.shape[0]):\n",
    "    lasso_squared_error += np.square(test.iloc[i][0] - test_predictions[i])\n",
    "# mean squared error\n",
    "lasso_squared_error / len(test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
